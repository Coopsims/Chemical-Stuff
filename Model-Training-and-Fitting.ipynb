{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508c25c15961501",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import csv\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import config\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import vstack, hstack, csr_matrix\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ],
   "id": "7bfe554502c925ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = train_df.drop(['id', 'binds'], axis=1)\n",
    "y_train = train_df['binds']\n",
    "\n",
    "X_test = test_df.drop(['id', 'binds'], axis=1)\n",
    "y_test = test_df['binds']"
   ],
   "id": "819c921594620647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert string lists to actual lists\n",
    "X_train['molVector'] = X_train['molVector']\n",
    "print(X_train.dtypes)\n",
    "print(X_train.columns)"
   ],
   "id": "2a52a5bb88263be2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize OneHotEncoder for categorical variable transformation\n",
    "encoder = OneHotEncoder(sparse_output=True)\n",
    "print('Generating encoder values...')\n",
    "# Fit the encoder on the 'Protein_numeric' data from the training set\n",
    "encoder.fit(train_df[['Protein_numeric']])\n",
    "\n",
    "print('Applying values to training dataframe...')\n",
    "# Transform 'Protein_numeric' for the training dataset\n",
    "protein_onehot_train = encoder.transform(train_df[['Protein_numeric']])\n",
    "print('Applying values to testing dataframe...')\n",
    "# Transform 'Protein_numeric' for the testing dataset using the same encoder\n",
    "protein_onehot_test = encoder.transform(test_df[['Protein_numeric']])\n",
    "\n",
    "# Check if 'molVector' needs to be converted to a sparse matrix\n",
    "if isinstance(train_df['molVector'].iloc[0], np.ndarray):\n",
    "    molVector_train_sparse = csr_matrix(np.vstack(train_df['molVector']))\n",
    "    molVector_test_sparse = csr_matrix(np.vstack(test_df['molVector']))\n",
    "else:\n",
    "    molVector_train_sparse = csr_matrix(train_df['molVector'].tolist())\n",
    "    molVector_test_sparse = csr_matrix(test_df['molVector'].tolist())\n",
    "\n",
    "# Use hstack to concatenate 'molVector' with one-hot encoded 'Protein_numeric' vectors\n",
    "X_train = hstack([molVector_train_sparse, protein_onehot_train])\n",
    "X_test = hstack([molVector_test_sparse, protein_onehot_test])\n",
    "\n",
    "# Directly use 'binds' column for targets\n",
    "y_train = train_df['binds'].values\n",
    "y_test = test_df['binds'].values"
   ],
   "id": "fd35c8e5f32bab96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "del train_df, test_df\n",
    "del SMOTE, TanimotoSimilarity, RandomForestClassifier\n",
    "del protein_onehot_train, protein_onehot_test\n",
    "gc.collect()"
   ],
   "id": "32c8896ecb885420"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_data_in_chunks(X_data, y_data, chunk_size=100000):\n",
    "    X_data = np.array(X_data)  # Convert list to NumPy array\n",
    "    y_data = np.array(y_data)  # Convert list to NumPy array\n",
    "    n_samples = X_data.shape[0]\n",
    "    for start in range(0, n_samples, chunk_size):\n",
    "        end = start + chunk_size\n",
    "        yield X_data[start:end], y_data[start:end]\n",
    "\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model_params = {'n_estimators': 100, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1}\n",
    "\n",
    "# Training the model in chunks\n",
    "first_chunk = True\n",
    "for X_chunk, y_chunk in load_data_in_chunks(X_train, y_train):\n",
    "    dtrain = xgb.DMatrix(X_chunk, label=y_chunk)\n",
    "    if first_chunk:\n",
    "        model = xgb.train(model_params, dtrain, num_boost_round=10)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        bst = model.train(model_params, dtrain, num_boost_round=10, xgb_model=model)\n"
   ],
   "id": "e4c7b7ebe3591a56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Precision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\", recall_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC Score:\", roc_auc)\n"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
