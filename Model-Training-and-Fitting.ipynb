{
 "cells": [
  {
   "cell_type": "code",
   "id": "8508c25c15961501",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T01:58:45.506048Z",
     "start_time": "2024-04-23T01:58:43.474156Z"
    }
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import csv\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import config\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import vstack, hstack, csr_matrix\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import average_precision_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:11:17.576348Z",
     "start_time": "2024-04-23T03:10:48.656181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train_data_strings.csv')\n",
    "test_df = pd.read_csv('test_data_strings.csv')"
   ],
   "id": "7bfe554502c925ca",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:15:28.152675Z",
     "start_time": "2024-04-23T03:11:17.578332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df['molVector'] = train_df['molVector'].apply(lambda x: [int(i) for i in x.split(',')])\n",
    "test_df['molVector'] = test_df['molVector'].apply(lambda x: [int(i) for i in x.split(',')])"
   ],
   "id": "fd1855cbab7f54c0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:15:28.167866Z",
     "start_time": "2024-04-23T03:15:28.154157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_row_vector = train_df['molVector'].iloc[0]\n",
    "max_len = len(first_row_vector)\n",
    "print(max_len)"
   ],
   "id": "c837379f9f2d5429",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-23T03:15:28.170867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"about 6 minutes for this code\"\"\"\n",
    "molVector_train_df = pd.DataFrame(train_df['molVector'].to_list(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])\n",
    "molVector_test_df = pd.DataFrame(test_df['molVector'].to_list(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])"
   ],
   "id": "68a084f124122c20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(molVector_train_df.dtypes)",
   "id": "96ca5450c32aa652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Takes around 12 minutes for this code\"\"\"\n",
    "for col in molVector_train_df.columns:\n",
    "    molVector_train_df[col] = molVector_train_df[col].astype(np.int8)\n",
    "print('Changed type to int8...')\n",
    "train_df = pd.concat([train_df.drop(['molVector'], axis=1), molVector_train_df], axis=1)\n",
    "print('combined training set...')\n",
    "\n",
    "for col in molVector_test_df.columns:\n",
    "    molVector_test_df[col] = molVector_test_df[col].astype(np.int8)\n",
    "print('Changed type to int8...')\n",
    "test_df = pd.concat([test_df.drop(['molVector'], axis=1), molVector_test_df], axis=1)\n",
    "print('combined testing set...')\n"
   ],
   "id": "c1ad8c79f0cf5121",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop 'id' column from training and testing data\n",
    "train_df = train_df.drop(columns=['id'])\n",
    "test_df = test_df.drop(columns=['id'])\n",
    "\n",
    "# Define target variable for training data\n",
    "y_train = train_df['binds']\n",
    "X_train = train_df.drop(columns=['binds'])\n",
    "\n",
    "# Define target variable for testing data (if applicable)\n",
    "y_test = test_df['binds']\n",
    "X_test = test_df.drop(columns=['binds'])\n"
   ],
   "id": "2a52a5bb88263be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "del train_df, test_df\n",
    "del SMOTE, TanimotoSimilarity, RandomForestClassifier\n",
    "gc.collect()"
   ],
   "id": "fd35c8e5f32bab96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:21:45.262354Z",
     "start_time": "2024-04-23T02:21:26.016615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create XGBoost specific DMatrix data format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ],
   "id": "44f18d2985621c22",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:21:45.277192Z",
     "start_time": "2024-04-23T02:21:45.263359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# params = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'n_estimators': 10,\n",
    "#     'seed': 42,\n",
    "#     'eta': 0.01,\n",
    "#     'alpha': 10,\n",
    "#     'max_depth': 5,\n",
    "# }\n",
    "# \n",
    "# # Perform cross-validation\n",
    "# cv_results = xgb.cv(\n",
    "#     params,\n",
    "#     dtrain,\n",
    "#     num_boost_round=50,\n",
    "#     seed=42,\n",
    "#     nfold=5,\n",
    "#     metrics={\"error\", \"logloss\"},\n",
    "#     early_stopping_rounds=10\n",
    "# )\n",
    "# \n",
    "# # Print cross-validation results\n",
    "# print(cv_results)\n"
   ],
   "id": "b5727cf609ad98d0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:22:09.340743Z",
     "start_time": "2024-04-23T02:21:45.278191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  \n",
    "    'n_estimators': 100,  \n",
    "    'learning_rate':0.01,\n",
    "    'alpha': 30,\n",
    "    'max_depth': 3,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Train model\n",
    "model = xgb.train(params, dtrain)"
   ],
   "id": "635d3ab467f92d8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:45] WARNING: C:\\b\\abs_7diruzi3as\\croot\\xgboost-split_1712794727514\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:22:09.356271Z",
     "start_time": "2024-04-23T02:22:09.342246Z"
    }
   },
   "cell_type": "code",
   "source": "model.save_model('xgb_model.json')",
   "id": "494a70ee1b1bb55c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:10:21.375944Z",
     "start_time": "2024-04-23T03:10:12.147921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make the prediction\n",
    "raw_predictions_train = model.predict(dtrain)\n",
    "\n",
    "# Create a dataframe with the predicted probabilities\n",
    "probabilities_train = pd.DataFrame(raw_predictions_train)\n",
    "print(probabilities_train.head())\n",
    "\n",
    "# Convert probabilities into binary output\n",
    "predictions_train = [1 if proba > 0.5 else 0 for proba in raw_predictions_train]\n",
    "\n",
    "# Now print the accuracy with these classes\n",
    "print(\"Accuracy:\", accuracy_score(y_train, predictions_train))\n",
    "print(\"Precision:\", precision_score(y_train, predictions_train))\n",
    "print(\"Recall:\", recall_score(y_train, predictions_train))\n",
    "print(\"F1 Score:\", f1_score(y_train, predictions_train))\n",
    "\n",
    "print(classification_report(y_train, predictions_train, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_train, predictions_train)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_train)\n",
    "\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, probabilities_train)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "print(\"AUC Score (Training):\", roc_auc_train)\n",
    "\n",
    "# Average Precision Score\n",
    "average_precision_train = average_precision_score(y_train, probabilities_train)\n",
    "print('Mean Average Precision (Training): {0:0.2f}'.format(average_precision_train))\n"
   ],
   "id": "147c8999a8b17bf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.452714\n",
      "1  0.547786\n",
      "2  0.547786\n",
      "3  0.452714\n",
      "4  0.547786\n",
      "Accuracy: 0.997371\n",
      "Precision: 1.0\n",
      "Recall: 0.994742\n",
      "F1 Score: 0.9973640701403991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      1.00      1.00   1000000\n",
      "     Class 1       1.00      0.99      1.00   1000000\n",
      "\n",
      "    accuracy                           1.00   2000000\n",
      "   macro avg       1.00      1.00      1.00   2000000\n",
      "weighted avg       1.00      1.00      1.00   2000000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1000000       0]\n",
      " [   5258  994742]]\n",
      "AUC Score (Training): 0.9973719999999999\n",
      "Mean Average Precision (Training): 1.00\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:10:35.801634Z",
     "start_time": "2024-04-23T03:10:32.968647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make the prediction\n",
    "raw_predictions = model.predict(dtest)\n",
    "\n",
    "# Create a dataframe with the predicted probabilities  \n",
    "probabilities = pd.DataFrame(raw_predictions)\n",
    "print(probabilities.head())\n",
    "\n",
    "# Convert probabilities into binary output\n",
    "predictions = [1 if proba > 0.5 else 0 for proba in raw_predictions]\n",
    "\n",
    "# Now print the accuracy with these classes\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Precision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\", recall_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"AUC Score:\", roc_auc)\n",
    "\n",
    "# Average Precision Score\n",
    "average_precision = average_precision_score(y_test, probabilities)\n",
    "print('Mean Average Precision (micro): {0:0.2f}'.format(average_precision))"
   ],
   "id": "32c8896ecb885420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.547786\n",
      "1  0.547786\n",
      "2  0.547786\n",
      "3  0.547786\n",
      "4  0.547786\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1179812, 1674896]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m proba \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m proba \u001B[38;5;129;01min\u001B[39;00m raw_predictions]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Now print the accuracy with these classes\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrecision:\u001B[39m\u001B[38;5;124m\"\u001B[39m, precision_score(y_test, predictions))\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecall:\u001B[39m\u001B[38;5;124m\"\u001B[39m, recall_score(y_test, predictions))\n",
      "File \u001B[1;32m~\\AppData\\Local\\r-miniconda\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    187\u001B[0m validate_parameter_constraints(\n\u001B[0;32m    188\u001B[0m     parameter_constraints, params, caller_name\u001B[38;5;241m=\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[0;32m    189\u001B[0m )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    202\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\r-miniconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 221\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\r-miniconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[0;32m     60\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 86\u001B[0m     \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     88\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\r-miniconda\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    395\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 397\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    398\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    399\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    400\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1179812, 1674896]"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:27:50.885872Z",
     "start_time": "2024-04-23T02:27:50.870853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def connect_to_database():\n",
    "    \"\"\"Connect to the MySQL database using settings from the config module.\"\"\"\n",
    "    try:\n",
    "        print(\"Connecting to the MySQL database...\")\n",
    "        conn = mysql.connector.connect(**config.DATABASE_CONFIG)\n",
    "        if conn.is_connected():\n",
    "            print(\"Connection established.\")\n",
    "        else:\n",
    "            print(\"Connection failed.\")\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        return None\n",
    "\n",
    "def close_connection(conn):\n",
    "    \"\"\"Close the database connection.\"\"\"\n",
    "    if conn.is_connected():\n",
    "        conn.close()\n",
    "        print(\"The connection is closed.\")\n",
    "\n",
    "def fetch_protein_mapping(cursor):\n",
    "    \"\"\"Fetch protein name to numeric mapping from the database.\"\"\"\n",
    "    query = \"SELECT protein_name, protein_numeric FROM protein_mapping\"\n",
    "    cursor.execute(query)\n",
    "    mapping_data = cursor.fetchall()\n",
    "    print('fetched protein mapping...')\n",
    "    return {name: num for name, num in mapping_data}"
   ],
   "id": "f4bbd9e9df0355ba",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:47:53.721022Z",
     "start_time": "2024-04-23T02:27:51.963478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load CSV data\n",
    "test_submission_data = pd.read_csv('leash-BELKA/test.csv')\n",
    "\n",
    "# Function to convert SMILES string to a fingerprint\n",
    "def smiles_to_fingerprint(smiles, radius=2, nBits=512):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return list(AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits))\n",
    "    else:\n",
    "        return [0]*nBits  # Return a zero vector if the molecule parsing fails\n",
    "\n",
    "# Process SMILES strings in batches\n",
    "def process_in_batches(smiles_series, batch_size=1000):\n",
    "    num_batches = (len(smiles_series) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "        batch = smiles_series.iloc[i*batch_size:(i+1)*batch_size].apply(smiles_to_fingerprint)\n",
    "        results.extend(batch)\n",
    "    return pd.Series(results)\n",
    "\n",
    "# Create dataframe and process fingerprints\n",
    "test_submission_df = pd.DataFrame()\n",
    "test_submission_df['id'] = test_submission_data['id']\n",
    "test_submission_df['molecule_smiles'] = process_in_batches(test_submission_data['molecule_smiles'], batch_size=500)"
   ],
   "id": "d3c66aa197009955",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 3350/3350 [19:59<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:48:19.538561Z",
     "start_time": "2024-04-23T02:48:19.508989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you have a way to fetch protein mappings similar to the database method shown\n",
    "\n",
    "conn = connect_to_database()\n",
    "cursor = conn.cursor()\n",
    "protein_mapping = fetch_protein_mapping(cursor)\n",
    "cursor.close()\n",
    "conn.close()"
   ],
   "id": "efdd1834c501f582",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the MySQL database...\n",
      "Connection established.\n",
      "fetched protein mapping...\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:48:40.790542Z",
     "start_time": "2024-04-23T02:48:40.698885Z"
    }
   },
   "cell_type": "code",
   "source": "test_submission_df['Protein_numeric'] = test_data['protein_name'].map(protein_mapping)",
   "id": "42a4775d9ec165b6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:59:09.056790Z",
     "start_time": "2024-04-23T02:49:12.518765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust based on your fingerprint length\n",
    "\"\"\"Expect about 9 minutes for this code\"\"\"\n",
    "molVector_test_df = pd.DataFrame(test_submission_df['molecule_smiles'].tolist(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])\n",
    "print('converted to many columns...')\n",
    "for col in molVector_test_df.columns:\n",
    "    molVector_test_df[col] = molVector_test_df[col].astype(np.int8)\n",
    "print('Converted type to int8...')\n",
    "test_submission_df = pd.concat([test_submission_df.drop(['molecule_smiles'], axis=1), molVector_test_df], axis=1)"
   ],
   "id": "e111281775d20153",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted type to int8 and reshaped the dataframe...\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To load model\n",
    "model = xgb.Booster()\n",
    "model.load_model('xgb_model.json')"
   ],
   "id": "951c6bfef0e1add3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:03:36.513800Z",
     "start_time": "2024-04-23T03:03:24.417468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Prepare data for prediction\n",
    "dtest1 = xgb.DMatrix(test_submission_df.drop(['id'], axis=1))"
   ],
   "id": "1aa1f742b7234d3f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:04:41.828068Z",
     "start_time": "2024-04-23T03:04:41.576700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_predictions = model.predict(dtest1)\n",
    "\n",
    "# Save predictions\n",
    "test_submission_df['binds'] = raw_predictions"
   ],
   "id": "2925e1294a9ce4bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\funkb\\AppData\\Local\\Temp\\ipykernel_2428\\2523094138.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df['binds'] = raw_predictions\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:05:25.978931Z",
     "start_time": "2024-04-23T03:05:23.532962Z"
    }
   },
   "cell_type": "code",
   "source": "test_submission_df[['id', 'binds']].to_csv('Submission2XGBoost.csv', index=False)",
   "id": "430e73e00f9774c3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "10473071ec225741",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
