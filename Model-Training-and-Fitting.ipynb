{
 "cells": [
  {
   "cell_type": "code",
   "id": "8508c25c15961501",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T01:58:45.506048Z",
     "start_time": "2024-04-23T01:58:43.474156Z"
    }
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import csv\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import config\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import vstack, hstack, csr_matrix\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import average_precision_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:11:17.576348Z",
     "start_time": "2024-04-23T03:10:48.656181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train_data_strings.csv')\n",
    "test_df = pd.read_csv('test_data_strings.csv')"
   ],
   "id": "7bfe554502c925ca",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:15:28.152675Z",
     "start_time": "2024-04-23T03:11:17.578332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df['molVector'] = train_df['molVector'].apply(lambda x: [int(i) for i in x.split(',')])\n",
    "test_df['molVector'] = test_df['molVector'].apply(lambda x: [int(i) for i in x.split(',')])"
   ],
   "id": "fd1855cbab7f54c0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:15:28.167866Z",
     "start_time": "2024-04-23T03:15:28.154157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_row_vector = train_df['molVector'].iloc[0]\n",
    "max_len = len(first_row_vector)\n",
    "print(max_len)"
   ],
   "id": "c837379f9f2d5429",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:21:32.059812Z",
     "start_time": "2024-04-23T03:15:28.170867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"about 6 minutes for this code\"\"\"\n",
    "molVector_train_df = pd.DataFrame(train_df['molVector'].to_list(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])\n",
    "molVector_test_df = pd.DataFrame(test_df['molVector'].to_list(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])"
   ],
   "id": "68a084f124122c20",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:21:32.074848Z",
     "start_time": "2024-04-23T03:21:32.061812Z"
    }
   },
   "cell_type": "code",
   "source": "print(molVector_train_df.dtypes)",
   "id": "96ca5450c32aa652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molVect1      int64\n",
      "molVect2      int64\n",
      "molVect3      int64\n",
      "molVect4      int64\n",
      "molVect5      int64\n",
      "              ...  \n",
      "molVect508    int64\n",
      "molVect509    int64\n",
      "molVect510    int64\n",
      "molVect511    int64\n",
      "molVect512    int64\n",
      "Length: 512, dtype: object\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:33:44.118081Z",
     "start_time": "2024-04-23T03:21:32.076848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Takes around 12 minutes for this code\"\"\"\n",
    "for col in molVector_train_df.columns:\n",
    "    molVector_train_df[col] = molVector_train_df[col].astype(np.int8)\n",
    "print('Changed type to int8...')\n",
    "train_df = pd.concat([train_df.drop(['molVector'], axis=1), molVector_train_df], axis=1)\n",
    "print('combined training set...')\n",
    "\n",
    "for col in molVector_test_df.columns:\n",
    "    molVector_test_df[col] = molVector_test_df[col].astype(np.int8)\n",
    "print('Changed type to int8...')\n",
    "test_df = pd.concat([test_df.drop(['molVector'], axis=1), molVector_test_df], axis=1)\n",
    "print('combined testing set...')\n"
   ],
   "id": "c1ad8c79f0cf5121",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed type to int8...\n",
      "combined training set...\n",
      "Changed type to int8...\n",
      "combined testing set...\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:33:49.744462Z",
     "start_time": "2024-04-23T03:33:44.119080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop 'id' column from training and testing data\n",
    "train_df = train_df.drop(columns=['id'])\n",
    "test_df = test_df.drop(columns=['id'])\n",
    "\n",
    "# Define target variable for training data\n",
    "y_train = train_df['binds']\n",
    "X_train = train_df.drop(columns=['binds'])\n",
    "\n",
    "# Define target variable for testing data (if applicable)\n",
    "y_test = test_df['binds']\n",
    "X_test = test_df.drop(columns=['binds'])\n"
   ],
   "id": "2a52a5bb88263be2",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:33:49.838339Z",
     "start_time": "2024-04-23T03:33:49.746462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del train_df, test_df\n",
    "gc.collect()"
   ],
   "id": "fd35c8e5f32bab96",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m train_df, test_df\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m SMOTE, TanimotoSimilarity, RandomForestClassifier\n\u001B[0;32m      3\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XGBoost Training",
   "id": "c009fee7fcf48b3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:35:46.124299Z",
     "start_time": "2024-04-23T03:35:25.616051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create XGBoost specific DMatrix data format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ],
   "id": "44f18d2985621c22",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:21:45.277192Z",
     "start_time": "2024-04-23T02:21:45.263359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# params = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'n_estimators': 10,\n",
    "#     'seed': 42,\n",
    "#     'eta': 0.01,\n",
    "#     'alpha': 10,\n",
    "#     'max_depth': 5,\n",
    "# }\n",
    "# \n",
    "# # Perform cross-validation\n",
    "# cv_results = xgb.cv(\n",
    "#     params,\n",
    "#     dtrain,\n",
    "#     num_boost_round=50,\n",
    "#     seed=42,\n",
    "#     nfold=5,\n",
    "#     metrics={\"error\", \"logloss\"},\n",
    "#     early_stopping_rounds=10\n",
    "# )\n",
    "# \n",
    "# # Print cross-validation results\n",
    "# print(cv_results)\n"
   ],
   "id": "b5727cf609ad98d0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T04:01:12.026247Z",
     "start_time": "2024-04-23T04:00:48.760181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 1000,  \n",
    "    'learning_rate':0.005,\n",
    "    'alpha': 10,  \n",
    "    'lambda': 1,  \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 50,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Train model\n",
    "model = xgb.train(params, dtrain)"
   ],
   "id": "635d3ab467f92d8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:00:48] WARNING: C:\\b\\abs_7diruzi3as\\croot\\xgboost-split_1712794727514\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:22:09.356271Z",
     "start_time": "2024-04-23T02:22:09.342246Z"
    }
   },
   "cell_type": "code",
   "source": "model.save_model('xgb_model.json')",
   "id": "494a70ee1b1bb55c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural Network",
   "id": "42b8373e16c79a9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:59:27.336949Z",
     "start_time": "2024-04-23T03:59:27.307701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available: \", cuda_available)\n",
    "\n",
    "# Get the number of GPUs available\n",
    "if cuda_available:\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of GPUs Available: \", num_gpus)\n",
    "    for i in range(num_gpus):\n",
    "        print(\"GPU \", i, \": \", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"No GPU available, using CPU instead.\")\n"
   ],
   "id": "78432d2478668b18",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Check if CUDA is available\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m cuda_available \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241m.\u001B[39mis_available()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA Available: \u001B[39m\u001B[38;5;124m\"\u001B[39m, cuda_available)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Get the number of GPUs available\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:59:22.378726Z",
     "start_time": "2024-04-23T03:59:22.364215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ],
   "id": "65e9d6ed044f35a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch Version:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__version__\u001B[49m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA Available:\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available())\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Results",
   "id": "6adc90fb8acba23d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T04:01:28.993799Z",
     "start_time": "2024-04-23T04:01:19.119348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make the prediction\n",
    "raw_predictions_train = model.predict(dtrain)\n",
    "\n",
    "# Create a dataframe with the predicted probabilities\n",
    "probabilities_train = pd.DataFrame(raw_predictions_train)\n",
    "print(probabilities_train.head())\n",
    "\n",
    "# Convert probabilities into binary output\n",
    "predictions_train = [1 if proba > 0.5 else 0 for proba in raw_predictions_train]\n",
    "\n",
    "# Now print the accuracy with these classes\n",
    "print(\"Accuracy:\", accuracy_score(y_train, predictions_train))\n",
    "print(\"Precision:\", precision_score(y_train, predictions_train))\n",
    "print(\"Recall:\", recall_score(y_train, predictions_train))\n",
    "print(\"F1 Score:\", f1_score(y_train, predictions_train))\n",
    "\n",
    "print(classification_report(y_train, predictions_train, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_train, predictions_train)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_train)\n",
    "\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, probabilities_train)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "print(\"AUC Score (Training):\", roc_auc_train)\n",
    "\n",
    "# Average Precision Score\n",
    "average_precision_train = average_precision_score(y_train, probabilities_train)\n",
    "print('Mean Average Precision (Training): {0:0.2f}'.format(average_precision_train))\n"
   ],
   "id": "147c8999a8b17bf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.475814\n",
      "1  0.524442\n",
      "2  0.524442\n",
      "3  0.475814\n",
      "4  0.524442\n",
      "Accuracy: 0.9973715\n",
      "Precision: 1.0\n",
      "Recall: 0.994743\n",
      "F1 Score: 0.997364572779551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      1.00      1.00   1000000\n",
      "     Class 1       1.00      0.99      1.00   1000000\n",
      "\n",
      "    accuracy                           1.00   2000000\n",
      "   macro avg       1.00      1.00      1.00   2000000\n",
      "weighted avg       1.00      1.00      1.00   2000000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1000000       0]\n",
      " [   5257  994743]]\n",
      "AUC Score (Training): 0.9973719999999999\n",
      "Mean Average Precision (Training): 1.00\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T04:01:34.286959Z",
     "start_time": "2024-04-23T04:01:28.994775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make the prediction\n",
    "raw_predictions = model.predict(dtest)\n",
    "\n",
    "# Create a dataframe with the predicted probabilities  \n",
    "probabilities = pd.DataFrame(raw_predictions)\n",
    "print(probabilities.head())\n",
    "\n",
    "# Convert probabilities into binary output\n",
    "predictions = [1 if proba > 0.5 else 0 for proba in raw_predictions]\n",
    "\n",
    "# Now print the accuracy with these classes\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Precision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\", recall_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"AUC Score:\", roc_auc)\n",
    "\n",
    "# Average Precision Score\n",
    "average_precision = average_precision_score(y_test, probabilities)\n",
    "print('Mean Average Precision (micro): {0:0.2f}'.format(average_precision))"
   ],
   "id": "32c8896ecb885420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.524442\n",
      "1  0.524442\n",
      "2  0.524442\n",
      "3  0.524442\n",
      "4  0.524412\n",
      "Accuracy: 0.5733727068380386\n",
      "Precision: 0.5396096777086548\n",
      "Recall: 0.9995694229250084\n",
      "F1 Score: 0.7008636407938935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.15      0.26    589906\n",
      "     Class 1       0.54      1.00      0.70    589906\n",
      "\n",
      "    accuracy                           0.57   1179812\n",
      "   macro avg       0.77      0.57      0.48   1179812\n",
      "weighted avg       0.77      0.57      0.48   1179812\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 86820 503086]\n",
      " [   254 589652]]\n",
      "AUC Score: 0.9889508116939492\n",
      "Mean Average Precision (micro): 0.99\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code for Creating Submission Using Model",
   "id": "3a876e7121b8a490"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:27:50.885872Z",
     "start_time": "2024-04-23T02:27:50.870853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def connect_to_database():\n",
    "    \"\"\"Connect to the MySQL database using settings from the config module.\"\"\"\n",
    "    try:\n",
    "        print(\"Connecting to the MySQL database...\")\n",
    "        conn = mysql.connector.connect(**config.DATABASE_CONFIG)\n",
    "        if conn.is_connected():\n",
    "            print(\"Connection established.\")\n",
    "        else:\n",
    "            print(\"Connection failed.\")\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        return None\n",
    "\n",
    "def close_connection(conn):\n",
    "    \"\"\"Close the database connection.\"\"\"\n",
    "    if conn.is_connected():\n",
    "        conn.close()\n",
    "        print(\"The connection is closed.\")\n",
    "\n",
    "def fetch_protein_mapping(cursor):\n",
    "    \"\"\"Fetch protein name to numeric mapping from the database.\"\"\"\n",
    "    query = \"SELECT protein_name, protein_numeric FROM protein_mapping\"\n",
    "    cursor.execute(query)\n",
    "    mapping_data = cursor.fetchall()\n",
    "    print('fetched protein mapping...')\n",
    "    return {name: num for name, num in mapping_data}"
   ],
   "id": "f4bbd9e9df0355ba",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:47:53.721022Z",
     "start_time": "2024-04-23T02:27:51.963478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load CSV data\n",
    "test_submission_data = pd.read_csv('leash-BELKA/test.csv')\n",
    "\n",
    "# Function to convert SMILES string to a fingerprint\n",
    "def smiles_to_fingerprint(smiles, radius=2, nBits=512):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return list(AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits))\n",
    "    else:\n",
    "        return [0]*nBits  # Return a zero vector if the molecule parsing fails\n",
    "\n",
    "# Process SMILES strings in batches\n",
    "def process_in_batches(smiles_series, batch_size=1000):\n",
    "    num_batches = (len(smiles_series) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "        batch = smiles_series.iloc[i*batch_size:(i+1)*batch_size].apply(smiles_to_fingerprint)\n",
    "        results.extend(batch)\n",
    "    return pd.Series(results)\n",
    "\n",
    "# Create dataframe and process fingerprints\n",
    "test_submission_df = pd.DataFrame()\n",
    "test_submission_df['id'] = test_submission_data['id']\n",
    "test_submission_df['molecule_smiles'] = process_in_batches(test_submission_data['molecule_smiles'], batch_size=500)"
   ],
   "id": "d3c66aa197009955",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 3350/3350 [19:59<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:48:19.538561Z",
     "start_time": "2024-04-23T02:48:19.508989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you have a way to fetch protein mappings similar to the database method shown\n",
    "\n",
    "conn = connect_to_database()\n",
    "cursor = conn.cursor()\n",
    "protein_mapping = fetch_protein_mapping(cursor)\n",
    "cursor.close()\n",
    "conn.close()"
   ],
   "id": "efdd1834c501f582",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the MySQL database...\n",
      "Connection established.\n",
      "fetched protein mapping...\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:48:40.790542Z",
     "start_time": "2024-04-23T02:48:40.698885Z"
    }
   },
   "cell_type": "code",
   "source": "test_submission_df['Protein_numeric'] = test_data['protein_name'].map(protein_mapping)",
   "id": "42a4775d9ec165b6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:59:09.056790Z",
     "start_time": "2024-04-23T02:49:12.518765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust based on your fingerprint length\n",
    "\"\"\"Expect about 9 minutes for this code\"\"\"\n",
    "molVector_test_df = pd.DataFrame(test_submission_df['molecule_smiles'].tolist(), columns=[f\"molVect{i + 1}\" for i in range(max_len)])\n",
    "print('converted to many columns...')\n",
    "for col in molVector_test_df.columns:\n",
    "    molVector_test_df[col] = molVector_test_df[col].astype(np.int8)\n",
    "print('Converted type to int8...')\n",
    "test_submission_df = pd.concat([test_submission_df.drop(['molecule_smiles'], axis=1), molVector_test_df], axis=1)"
   ],
   "id": "e111281775d20153",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted type to int8 and reshaped the dataframe...\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To load model\n",
    "model = xgb.Booster()\n",
    "model.load_model('xgb_model.json')"
   ],
   "id": "951c6bfef0e1add3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:03:36.513800Z",
     "start_time": "2024-04-23T03:03:24.417468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Prepare data for prediction\n",
    "dtest1 = xgb.DMatrix(test_submission_df.drop(['id'], axis=1))"
   ],
   "id": "1aa1f742b7234d3f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:04:41.828068Z",
     "start_time": "2024-04-23T03:04:41.576700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_predictions = model.predict(dtest1)\n",
    "\n",
    "# Save predictions\n",
    "test_submission_df['binds'] = raw_predictions"
   ],
   "id": "2925e1294a9ce4bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\funkb\\AppData\\Local\\Temp\\ipykernel_2428\\2523094138.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df['binds'] = raw_predictions\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:05:25.978931Z",
     "start_time": "2024-04-23T03:05:23.532962Z"
    }
   },
   "cell_type": "code",
   "source": "test_submission_df[['id', 'binds']].to_csv('Submission2XGBoost.csv', index=False)",
   "id": "430e73e00f9774c3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "10473071ec225741",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
